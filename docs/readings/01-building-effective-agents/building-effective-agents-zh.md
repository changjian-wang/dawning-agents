# 构建高效的 Agent

> 原文链接: https://www.anthropic.com/research/building-effective-agents
> 发布日期: 2024年12月19日

我们与数十个跨行业构建 LLM Agent 的团队合作过。最成功的实现始终使用简单、可组合的模式，而非复杂的框架。

在过去一年中，我们与数十个跨行业构建大型语言模型（LLM）Agent 的团队合作。始终如一的是，最成功的实现并没有使用复杂的框架或专门的库。相反，它们使用简单、可组合的模式进行构建。

在这篇文章中，我们分享了与客户合作以及自己构建 Agent 的经验，并为开发者提供构建高效 Agent 的实用建议。

---

## 什么是 Agent？

"Agent" 可以有多种定义方式。一些客户将 Agent 定义为完全自主的系统，能够在较长时间内独立运行，使用各种工具来完成复杂任务。其他人则使用这个术语来描述遵循预定义工作流的更规范的实现。在 Anthropic，我们将所有这些变体归类为**智能体系统（agentic systems）**，但在架构上对**工作流（workflows）**和 **Agent** 做出了重要区分：

- **工作流（Workflows）** 是通过预定义代码路径编排 LLM 和工具的系统。
- **Agent** 则是 LLM 动态指导自身流程和工具使用的系统，保持对如何完成任务的控制权。

下面，我们将详细探讨这两种类型的智能体系统。在附录1（"Agent 实践"）中，我们描述了客户在使用这类系统中发现特别有价值的两个领域。

---

## 何时（以及何时不）使用 Agent

在使用 LLM 构建应用程序时，我们建议**找到最简单的可能解决方案**，只有在需要时才增加复杂性。这可能意味着根本不构建智能体系统。智能体系统通常以延迟和成本换取更好的任务性能，你应该考虑这种权衡何时有意义。

当需要更多复杂性时：
- **工作流** 为定义明确的任务提供可预测性和一致性
- **Agent** 是在需要灵活性和模型驱动决策时的更好选择

然而，对于许多应用程序来说，通过检索和上下文示例优化单个 LLM 调用通常就足够了。

---

## 何时以及如何使用框架

有许多框架可以使智能体系统更容易实现，包括：

- **Claude Agent SDK**
- **Strands Agents SDK**（AWS）
- **Rivet** - 拖放式 GUI LLM 工作流构建器
- **Vellum** - 另一个用于构建和测试复杂工作流的 GUI 工具

这些框架通过简化标准低级任务（如调用 LLM、定义和解析工具、链接调用）使入门变得容易。然而，它们通常会创建额外的抽象层，这可能会模糊底层的提示和响应，使调试变得更加困难。它们还可能诱使人们在更简单的设置就足够时添加不必要的复杂性。

我们建议开发者**从直接使用 LLM API 开始**：许多模式可以用几行代码实现。如果你确实使用框架，请确保你理解底层代码。对底层实现的错误假设是客户错误的常见来源。

请参阅我们的 cookbook 获取一些示例实现。

---

## 构建块、工作流和 Agent

在本节中，我们将探讨在生产中看到的智能体系统的常见模式。我们将从基础构建块——**增强型 LLM**——开始，逐步增加复杂性，从简单的组合工作流到自主 Agent。

### 构建块：增强型 LLM

智能体系统的基本构建块是通过**检索（retrieval）**、**工具（tools）**和**记忆（memory）**等增强功能增强的 LLM。我们当前的模型可以主动使用这些能力——生成自己的搜索查询、选择适当的工具，以及确定保留哪些信息。

我们建议关注实现的两个关键方面：
1. **根据你的特定用例定制这些能力**
2. **确保它们为你的 LLM 提供简单、文档完善的接口**

虽然有许多方法可以实现这些增强功能，但一种方法是通过我们最近发布的 **Model Context Protocol（MCP）**，它允许开发者通过简单的客户端实现与不断增长的第三方工具生态系统集成。

在本文的其余部分，我们假设每个 LLM 调用都可以访问这些增强能力。

### 工作流：提示链（Prompt Chaining）

提示链将任务分解为一系列步骤，其中每个 LLM 调用处理前一个调用的输出。你可以在任何中间步骤上添加编程检查（见下图中的"门"）以确保流程仍在正轨上。

**何时使用此工作流：** 此工作流非常适合任务可以轻松、干净地分解为固定子任务的情况。主要目标是通过使每个 LLM 调用成为更简单的任务来**用延迟换取更高的准确性**。

**提示链有用的示例：**

- 生成营销文案，然后将其翻译成另一种语言。
- 编写文档大纲，检查大纲是否满足某些标准，然后根据大纲编写文档。

### 工作流：路由（Routing）

路由对输入进行分类，并将其引导到专门的后续任务。此工作流允许关注点分离，并构建更专业的提示。没有此工作流，针对一种输入的优化可能会损害其他输入的性能。

**何时使用此工作流：** 路由适用于有明确类别且最好分别处理的复杂任务，并且可以由 LLM 或更传统的分类模型/算法准确处理分类。

**路由有用的示例：**

- 将不同类型的客户服务查询（一般问题、退款请求、技术支持）引导到不同的下游流程、提示和工具。
- 将简单/常见问题路由到更小、成本效益更高的模型（如 Claude Haiku 4.5），将困难/不常见问题路由到更强大的模型（如 Claude Sonnet 4.5）以优化性能。

### 工作流：并行化（Parallelization）

LLM 有时可以同时处理一个任务，并以编程方式聚合其输出。这种工作流——并行化——表现为两个关键变体：

- **分段（Sectioning）**：将任务分解为并行运行的独立子任务。
- **投票（Voting）**：多次运行相同任务以获得多样化的输出。

**何时使用此工作流：** 当划分的子任务可以并行化以提高速度，或需要多个视角或尝试以获得更高置信度的结果时，并行化是有效的。对于有多个考虑因素的复杂任务，当每个考虑因素由单独的 LLM 调用处理时，LLM 通常表现更好，允许对每个特定方面进行集中关注。

**并行化有用的示例：**

- **分段：**
  - 实现防护栏，其中一个模型实例处理用户查询，而另一个筛选不当内容或请求。这往往比让同一个 LLM 调用同时处理防护栏和核心响应表现更好。
  - 自动化评估以评估 LLM 性能，其中每个 LLM 调用评估模型在给定提示上表现的不同方面。

- **投票：**
  - 审查代码是否存在漏洞，其中几个不同的提示审查并在发现问题时标记代码。
  - 评估给定内容是否不当，使用多个提示评估不同方面或要求不同的投票阈值以平衡误报和漏报。

### 工作流：编排器-工作者（Orchestrator-Workers）

在编排器-工作者工作流中，中央 LLM 动态分解任务，将其委托给工作者 LLM，并综合它们的结果。

**何时使用此工作流：** 此工作流非常适合无法预测所需子任务的复杂任务（例如在编码中，需要更改的文件数量和每个文件中更改的性质可能取决于任务）。虽然在拓扑上相似，但与并行化的关键区别在于其**灵活性**——子任务不是预定义的，而是由编排器根据特定输入确定。

**编排器-工作者有用的示例：**

- 每次对多个文件进行复杂更改的编码产品。
- 涉及从多个来源收集和分析信息以获取可能相关信息的搜索任务。

### 工作流：评估器-优化器（Evaluator-Optimizer）

在评估器-优化器工作流中，一个 LLM 调用生成响应，而另一个在循环中提供评估和反馈。

**何时使用此工作流：** 当我们有明确的评估标准，且迭代改进提供可衡量的价值时，此工作流特别有效。适合的两个标志是：
1. 当人类表达反馈时，LLM 响应可以明显改进
2. LLM 可以提供这样的反馈

这类似于人类作家在制作精美文档时可能经历的迭代写作过程。

**评估器-优化器有用的示例：**

- 文学翻译，其中翻译 LLM 最初可能无法捕捉到的细微差别，但评估 LLM 可以提供有用的批评。
- 需要多轮搜索和分析以收集全面信息的复杂搜索任务，其中评估器决定是否需要进一步搜索。

### Agent

随着 LLM 在关键能力上成熟——理解复杂输入、进行推理和规划、可靠地使用工具以及从错误中恢复——Agent 正在生产中出现。Agent 通过与人类用户的命令或交互式讨论开始工作。一旦任务明确，Agent 就会独立计划和操作，可能会返回人类以获取更多信息或判断。在执行过程中，Agent 在每一步从环境中获得"基本事实"（如工具调用结果或代码执行）以评估其进度至关重要。Agent 可以在检查点或遇到阻碍时暂停以获取人类反馈。任务通常在完成时终止，但通常也会包含停止条件（如最大迭代次数）以保持控制。

Agent 可以处理复杂任务，但其实现通常很简单。它们通常只是**在循环中基于环境反馈使用工具的 LLM**。因此，清晰、周到地设计工具集及其文档至关重要。我们在附录2（"为你的工具进行提示工程"）中扩展了工具开发的最佳实践。

**何时使用 Agent：** Agent 可用于难以或不可能预测所需步骤数量的开放式问题，以及无法硬编码固定路径的情况。LLM 可能会运行许多轮次，你必须对其决策有一定程度的信任。Agent 的自主性使其非常适合在受信任的环境中扩展任务。

Agent 的自主性意味着更高的成本和可能的错误累积。我们建议在沙盒环境中进行广泛测试，并配备适当的防护栏。

**Agent 有用的示例：**

以下示例来自我们自己的实现：

- **编码 Agent** 用于解决 SWE-bench 任务，这涉及根据任务描述编辑多个文件；
- 我们的 **"计算机使用"参考实现**，其中 Claude 使用计算机完成任务。

---

## 组合和定制这些模式

这些构建块不是规定性的。它们是开发者可以塑造和组合以适应不同用例的常见模式。成功的关键，与任何 LLM 功能一样，是**衡量性能并迭代实现**。再次强调：只有当复杂性明显改善结果时，你才应该考虑增加复杂性。

---

## 总结

LLM 领域的成功不在于构建最复杂的系统，而在于**为你的需求构建正确的系统**。从简单的提示开始，通过全面评估优化它们，只有在更简单的解决方案不足时才添加多步骤智能体系统。

在实现 Agent 时，我们尝试遵循三个核心原则：

1. **保持 Agent 设计的简单性。**
2. **通过明确显示 Agent 的规划步骤来优先考虑透明度。**
3. **通过彻底的工具文档和测试精心设计你的 Agent-计算机接口（ACI）。**

框架可以帮助你快速入门，但在迁移到生产时不要犹豫减少抽象层并使用基本组件构建。遵循这些原则，你可以创建不仅强大，而且可靠、可维护且受用户信任的 Agent。

---

## 附录1：Agent 实践

我们与客户的合作揭示了 AI Agent 的两个特别有前途的应用，展示了上述讨论的模式的实用价值。这两个应用都说明了 Agent 如何为需要对话和行动、有明确成功标准、启用反馈循环和整合有意义的人类监督的任务增加最大价值。

### A. 客户支持

客户支持将熟悉的聊天机器人界面与通过工具集成增强的能力相结合。这非常适合更开放式的 Agent，因为：

- 支持交互自然地遵循对话流程，同时需要访问外部信息和操作；
- 工具可以集成以拉取客户数据、订单历史和知识库文章；
- 诸如发放退款或更新工单等操作可以以编程方式处理；
- 成功可以通过用户定义的解决方案清楚地衡量。

几家公司通过基于使用的定价模型展示了这种方法的可行性，该模型仅对成功解决方案收费，显示了对其 Agent 有效性的信心。

### B. 编码 Agent

软件开发领域已显示出 LLM 功能的巨大潜力，能力从代码完成发展到自主问题解决。Agent 特别有效，因为：

- 代码解决方案可以通过自动化测试验证；
- Agent 可以使用测试结果作为反馈迭代解决方案；
- 问题空间定义明确且结构化；
- 输出质量可以客观衡量。

在我们自己的实现中，Agent 现在可以仅根据拉取请求描述解决 SWE-bench Verified 基准测试中的真实 GitHub 问题。然而，虽然自动化测试有助于验证功能，但人工审查对于确保解决方案与更广泛的系统需求一致仍然至关重要。

---

## 附录2：为你的工具进行提示工程

无论你正在构建哪种智能体系统，工具都可能是你的 Agent 的重要组成部分。工具通过在我们的 API 中指定其确切结构和定义，使 Claude 能够与外部服务和 API 交互。当 Claude 响应时，如果它计划调用工具，它将在 API 响应中包含一个工具使用块。工具定义和规范应该像你的整体提示一样受到同样多的提示工程关注。在这个简短的附录中，我们描述如何为你的工具进行提示工程。

通常有几种方法可以指定相同的操作。例如，你可以通过编写 diff 或重写整个文件来指定文件编辑。对于结构化输出，你可以在 markdown 或 JSON 中返回代码。在软件工程中，这些差异是表面的，可以无损地相互转换。然而，某些格式对 LLM 来说比其他格式更难编写。编写 diff 需要在新代码编写之前知道块头中有多少行正在更改。在 JSON 中编写代码（与 markdown 相比）需要额外转义换行符和引号。

我们对工具格式决策的建议如下：

- **给模型足够的 token 来"思考"**，然后才把自己写入死角。
- **保持格式接近模型在互联网上自然出现的文本**中看到的内容。
- **确保没有格式"开销"**，例如必须保持数千行代码的准确计数，或字符串转义它编写的任何代码。

一个经验法则是考虑人机界面（HCI）投入了多少努力，并计划在创建良好的 Agent-计算机接口（ACI）上投入同样多的努力。以下是一些如何做到这一点的想法：

- **设身处地为模型着想。** 根据描述和参数，使用这个工具是否明显，还是你需要仔细考虑？如果是这样，那么模型可能也是如此。一个好的工具定义通常包括示例用法、边缘情况、输入格式要求以及与其他工具的明确边界。
- **如何更改参数名称或描述以使事情更明显？** 把这想象成为你团队中的初级开发者编写一个很好的文档字符串。当使用许多类似的工具时，这一点尤其重要。
- **测试模型如何使用你的工具：** 在我们的工作台中运行许多示例输入，看看模型犯了什么错误，然后迭代。
- **防错（Poka-yoke）你的工具。** 更改参数，使犯错更难。

在为 SWE-bench 构建我们的 Agent 时，我们实际上花了更多时间优化工具而不是整体提示。例如，我们发现在 Agent 移出根目录后，模型在使用相对文件路径的工具时会犯错。为了解决这个问题，我们更改了工具以始终要求绝对文件路径——我们发现模型完美地使用了这种方法。

---

## 致谢

由 Erik Schluntz 和 Barry Zhang 撰写。这项工作借鉴了我们在 Anthropic 构建 Agent 的经验以及客户分享的宝贵见解，我们对此深表感谢。
